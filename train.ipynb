{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Google conformer - Conformer: Convolution-augmented Transformer for Speech Recognition\n",
    "Apple - IMPROVING VISION-INSPIRED KEYWORD SPOTTING USING DYNAMIC MODULE\n",
    "SKIPPING IN STREAMING CONFORMER ENCODER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import psutil\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from model import Conformer\n",
    "from model import EmotionClassifier\n",
    "from model import GateLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "use_cpu = False\n",
    "\n",
    "if torch.cuda.is_available() and not use_cpu:\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "num_labels = 7\n",
    "learning_rate = 0.001 \n",
    "batch_size_train = 16\n",
    "batch_size_inference = 1\n",
    "blocks = 16 # conformer blocks\n",
    "dropout = 0.1 # effects the dropout all over the model\n",
    "inputdim = 40 # based on filter banks from the mfbs\n",
    "modeldim = 40 # hidden number of features the model works with\n",
    "subsamplereduction = 4 # reduces the time dimension at the start of the model by this factor\n",
    "feedforwardexpansion = 4 # increases the hidden dimension in the feed forward modules\n",
    "feedforwardweight = 0.5 # weight to ff modules\n",
    "pointwiseexpansion = 2 # don't alter, brought back by glu\n",
    "kernel_size = 31 # needs to be odd since we are using 'same' padding\n",
    "attentionheads = 4 # feel free to change\n",
    "temperature = 0.2 # if temp is low, the probabilities take more extreme values. \n",
    "gatethreshold = 0.5 # if Prob of execute > gatethreshold, execute\n",
    "gateregularizer = 0.2 # loss function parameter on gate_loss\n",
    "epochs = 10\n",
    "gate_activation = 0.1 # Determines when to turn gates on during training epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_int = {\n",
    "    \"Anger\": 0,\n",
    "    \"Disgust\": 1,\n",
    "    \"Fear\": 2,\n",
    "    \"Happy\": 3,\n",
    "    \"Sad\": 4,\n",
    "    \"Neutral\": 5,\n",
    "    \"Background\": 6,\n",
    "}\n",
    "\n",
    "def load_data():\n",
    "    train_features = np.load(\"data/train_features.npy\")\n",
    "    train_labels = np.load(\"data/train_labels.npy\")\n",
    "    testseen_features = np.load(\"data/testseen_features.npy\")\n",
    "    testseen_labels = np.load(\"data/testseen_labels.npy\")\n",
    "    testunseen_features = np.load(\"data/testunseen_features.npy\")\n",
    "    testunseen_labels = np.load(\"data/testunseen_labels.npy\")\n",
    "\n",
    "    # convert labels to integers so torch can use them\n",
    "    train_labels = np.array([label_to_int[label] for label in train_labels])\n",
    "    testseen_labels = np.array([label_to_int[label] for label in testseen_labels])\n",
    "    testunseen_labels = np.array([label_to_int[label] for label in testunseen_labels])\n",
    "\n",
    "    train_features_tensor = torch.tensor(train_features, dtype=torch.float32)\n",
    "    train_labels_tensor = torch.tensor(train_labels, dtype=torch.long)\n",
    "    testseen_features_tensor = torch.tensor(testseen_features, dtype=torch.float32)\n",
    "    testseen_labels_tensor = torch.tensor(testseen_labels, dtype=torch.long)\n",
    "    testunseen_features_tensor = torch.tensor(testunseen_features, dtype=torch.float32)\n",
    "    testunseen_labels_tensor = torch.tensor(testunseen_labels, dtype=torch.long)\n",
    "\n",
    "    train_dataset = TensorDataset(train_features_tensor, train_labels_tensor)\n",
    "    testseen_dataset = TensorDataset(testseen_features_tensor, testseen_labels_tensor)\n",
    "    testunseen_dataset = TensorDataset(testunseen_features_tensor, testunseen_labels_tensor)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size_train, shuffle=True)\n",
    "    train_loader_test = DataLoader(train_dataset, batch_size=batch_size_inference, shuffle=False) # For Batch Size 1\n",
    "    testseen_loader = DataLoader(testseen_dataset, batch_size=batch_size_inference, shuffle=False)\n",
    "    testunseen_loader = DataLoader(testunseen_dataset, batch_size=batch_size_inference, shuffle=False)\n",
    "    return train_loader, train_loader_test, testseen_loader, testunseen_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(gates_on):\n",
    "    conformer = Conformer(\n",
    "        inputdim,\n",
    "        modeldim,\n",
    "        subsamplereduction,\n",
    "        feedforwardexpansion,\n",
    "        feedforwardweight,\n",
    "        pointwiseexpansion,\n",
    "        kernel_size,\n",
    "        attentionheads,\n",
    "        blocks,\n",
    "        dropout,\n",
    "        temperature,\n",
    "        gatethreshold,\n",
    "        gates_on=gates_on\n",
    "    )\n",
    "    model = EmotionClassifier(conformer, num_labels, modeldim)\n",
    "    criterion = GateLoss(gateregularizer)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    return model, criterion, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, train_loader, epochs, gate_activation):\n",
    "    model.train()\n",
    "    gates_on = False\n",
    "    gate_activation_epoch = int(epochs * gate_activation)\n",
    "    max_mem_usage = 0.0\n",
    "    # for each parameter option in grid, run epochs on that option\n",
    "    for epoch in range(epochs):\n",
    "        start_time = time.time()\n",
    "        if epoch == gate_activation_epoch:\n",
    "            model.conformer.enable_gates()\n",
    "            gates_on = True\n",
    "            # freeze every parameter that isn't part of the gate module\n",
    "        current_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            model.conformer.reset_gate_values()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels, model.conformer.gate_values)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            current_loss += loss.item()\n",
    "            mem_usage = psutil.virtual_memory().used / 1e9  # in GB\n",
    "            if mem_usage > max_mem_usage:\n",
    "                max_mem_usage = mem_usage\n",
    "        epoch_time = time.time() - start_time\n",
    "        print(\n",
    "            f\"Epoch {epoch + 1} Gates {'On' if gates_on else 'Off'}, Loss: {(current_loss / len(train_loader)):.2f}, Time: {epoch_time:.2f} seconds, Memory Usage: {max_mem_usage:.2f} GB\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "skips = {\n",
    "    0: 0,\n",
    "    1: 0,\n",
    "    2: 0,\n",
    "    3: 0,\n",
    "    4: 0,\n",
    "    5: 0,\n",
    "    6: 0,\n",
    "}\n",
    "\n",
    "module_count = {\n",
    "    0: 0,\n",
    "    1: 0,\n",
    "    2: 0,\n",
    "    3: 0,\n",
    "    4: 0,\n",
    "    5: 0,\n",
    "    6: 0,\n",
    "}\n",
    "\n",
    "labels_actual = {\n",
    "    0: \"Anger\",\n",
    "    1: \"Disgust\",\n",
    "    2: \"Fear\",\n",
    "    3: \"Happy\",\n",
    "    4: \"Sad\",\n",
    "    5: \"Neutral\",\n",
    "    6: \"Background\",\n",
    "}\n",
    "\n",
    "def evaluate_model(model, loader, name):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    start_time = time.time()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for input, label in loader: # Batch size always 1\n",
    "            model.conformer.reset_gate_values()\n",
    "            input = input.to(device)\n",
    "            label = label.to(device)\n",
    "            output = model(input)\n",
    "            _, predicted = torch.max(output, 1)\n",
    "            total += label.size(0)\n",
    "            correct += (predicted == label).sum().item()\n",
    "\n",
    "            # calculate skips\n",
    "            emotion_key = label.item()\n",
    "            skips_current = torch.sum(model.conformer.gate_values <= gatethreshold).item()\n",
    "            module_count_current = model.conformer.gate_values.numel()\n",
    "            skips[emotion_key] += skips_current\n",
    "            module_count[emotion_key] += module_count_current\n",
    "\n",
    "    for i in range(num_labels):\n",
    "        skip_percentage = skips[i] / module_count[i]\n",
    "        print(f\"{name} {labels_actual[i]} skip percentage: {skip_percentage:.2f}\")\n",
    "    accuracy = 100 * correct / total\n",
    "    epoch_time = time.time() - start_time\n",
    "    print(f\"Accuracy on {name} Data: {accuracy}, Time: {epoch_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to add to evaluate - count number of modules skipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model, long):\n",
    "    all_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"Total Parameters: {all_params}\")\n",
    "    if long:\n",
    "        for name, module in model.named_modules():\n",
    "            if isinstance(module, nn.Module):\n",
    "                total_params = sum(p.numel() for p in module.parameters())\n",
    "                trainable_params = sum(\n",
    "                    p.numel() for p in module.parameters() if p.requires_grad\n",
    "                )\n",
    "                print(\n",
    "                    f\"{module.__class__.__name__} {name} - Total Parameters: {total_params}, Trainable Parameters: {trainable_params}\"\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_weights(model):\n",
    "    path = \"gated_conformer_model_weights.pth\"\n",
    "    torch.save(model.state_dict(), path)\n",
    "    print(f\"Model weights saved to {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_weights(model):\n",
    "    path = \"gated_conformer_model_weights.pth\"\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    print(f\"Model weights loaded from {path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_loader, testseen_loader, testunseen_loader = load_data()\n",
    "# model, criterion, optimizer = initialize_model(gates_on=True)\n",
    "# count_parameters(model, long=False)\n",
    "# with torch.no_grad():\n",
    "#     for inputs, labels in train_loader:\n",
    "#         outputs = model(inputs)\n",
    "#         loss = criterion(outputs, labels, model.conformer.gate_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we are doing right now is: epochs with gates activated at certain epoch num\n",
    "\n",
    "Things we can add: \n",
    "- grid search - temperature [0.1, 0.5, 1, 5], gateactivation [0, 0.25, 0.5, 0.75]\n",
    "- for each epoch, kfolds\n",
    "- freeze parameters\n",
    "- right now we are only getting accuracy, can get the full confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Parameters: 661900\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[205], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m criterion \u001b[38;5;241m=\u001b[39m criterion\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      5\u001b[0m count_parameters(model, long\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m----> 6\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgate_activation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m save_weights(model)\n\u001b[1;32m      8\u001b[0m evaluate_model(model, train_loader_test, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[199], line 19\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, train_loader, epochs, gate_activation)\u001b[0m\n\u001b[1;32m     17\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     18\u001b[0m model\u001b[38;5;241m.\u001b[39mconformer\u001b[38;5;241m.\u001b[39mreset_gate_values()\n\u001b[0;32m---> 19\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels, model\u001b[38;5;241m.\u001b[39mconformer\u001b[38;5;241m.\u001b[39mgate_values)\n\u001b[1;32m     21\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/448/project/gatedConformer/env/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/448/project/gatedConformer/env/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/448/project/gatedConformer/model.py:463\u001b[0m, in \u001b[0;36mEmotionClassifier.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m--> 463\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    464\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# could do max here, could add the standard deviation\u001b[39;00m\n\u001b[1;32m    465\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear(x)\n",
      "File \u001b[0;32m~/448/project/gatedConformer/env/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/448/project/gatedConformer/env/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/448/project/gatedConformer/model.py:451\u001b[0m, in \u001b[0;36mConformer.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;66;03m# Conformer Blocks\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks:\n\u001b[0;32m--> 451\u001b[0m     x, gates \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    452\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgate_values \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgate_values, gates))\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/448/project/gatedConformer/env/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/448/project/gatedConformer/env/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/448/project/gatedConformer/model.py:364\u001b[0m, in \u001b[0;36mBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    362\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn(x)\n\u001b[1;32m    363\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv(x)\n\u001b[0;32m--> 364\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mffweight \u001b[38;5;241m*\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mff2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    365\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_norm(x)\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x, gate_values\n",
      "File \u001b[0;32m~/448/project/gatedConformer/env/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/448/project/gatedConformer/env/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/448/project/gatedConformer/model.py:87\u001b[0m, in \u001b[0;36mFeedForward.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     85\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39msilu(x)\n\u001b[1;32m     86\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout1(x)\n\u001b[0;32m---> 87\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout2(x)\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/448/project/gatedConformer/env/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/448/project/gatedConformer/env/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/448/project/gatedConformer/env/lib/python3.11/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_loader, train_loader_test, testseen_loader, testunseen_loader = load_data()\n",
    "model, criterion, optimizer = initialize_model(gates_on=False) # gates are enabled during training based on gate_activation\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "count_parameters(model, long=False)\n",
    "train_model(model, criterion, optimizer, train_loader, epochs, gate_activation)\n",
    "save_weights(model)\n",
    "evaluate_model(model, train_loader_test, \"Train\")\n",
    "evaluate_model(model, testseen_loader, \"Test Seen\")\n",
    "evaluate_model(model, testunseen_loader, \"Test Uneen\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
